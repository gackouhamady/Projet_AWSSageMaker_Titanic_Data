{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.transformer import Transformer\n",
    "import sagemaker\n",
    "\n",
    "# Définir le nom du modèle et du fichier S3 contenant les données de test\n",
    "model_name = 'xgboost-titanic-model'  # Remplacez par le nom de votre modèle\n",
    "input_data_s3_path = f\"s3://{bucket_name}/processed/test_data.csv\"\n",
    "output_data_s3_path = f\"s3://{bucket_name}/predictions/output\"\n",
    "\n",
    "# Initialiser la session SageMaker et le rôle d'exécution\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Charger le modèle XGBoost déjà formé\n",
    "xgb_model = sagemaker.model.Model(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"xgboost\", region=\"eu-west-3\", version=\"1.2-1\"),\n",
    "    model_data=f\"s3://{bucket_name}/output/model.tar.gz\",  # Le chemin du modèle sauvegardé\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Créer un objet Transformer pour le Batch Transform\n",
    "transformer = xgb_model.transformer(\n",
    "    instance_count=1,  # Le nombre d'instances pour effectuer les prédictions\n",
    "    instance_type='ml.m5.large',  # Type d'instance à utiliser\n",
    "    strategy='SingleRecord',  # Pour effectuer des prédictions ligne par ligne\n",
    "    output_path=output_data_s3_path,  # Le chemin de sortie pour les résultats des prédictions\n",
    "    input_filter='$[0,-1]',  # Inclure toutes les colonnes, sauf la dernière (cible)\n",
    "    join_source='Input',  # Garder les colonnes de l'entrée intactes dans la sortie\n",
    "    content_type='text/csv',  # Format d'entrée des données\n",
    "    split_type='Line',  # Séparer chaque ligne comme un enregistrement\n",
    ")\n",
    "\n",
    "# Lancer le job Batch Transform\n",
    "transformer.transform(\n",
    "    data=input_data_s3_path,  # Données d'entrée pour les prédictions\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',  # Une ligne à la fois\n",
    "    input_filter='$[0,-1]',  # Inclure toutes les colonnes sauf la cible\n",
    "    join_source='Input',  # Joindre les prédictions aux entrées originales\n",
    "    output_filter='$[0,-1]',  # Inclure la première colonne et la dernière (la prédiction)\n",
    "    wait=True  # Attendre la fin du job avant de poursuivre\n",
    ")\n",
    "\n",
    "# Vérifier l'emplacement des prédictions\n",
    "print(f\"Les prédictions sont disponibles ici : {output_data_s3_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b200557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les résultats des prédictions\n",
    "s3.download_file(bucket_name, 'predictions/output/predictions.csv', 'predictions.csv')\n",
    "\n",
    "# Charger les résultats des prédictions\n",
    "predictions_df = pd.read_csv('predictions.csv')\n",
    "\n",
    "# Supposons que la première colonne est la prédiction\n",
    "predictions = predictions_df['predicted_label']\n",
    "\n",
    "# Charger les vraies valeurs de l'ensemble de test\n",
    "y_test = pd.read_csv('test_data.csv')['Survived']\n",
    "\n",
    "# Calculer l'accuracy\n",
    "accuracy = (predictions == y_test).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
